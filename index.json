[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a fourth year Computer Science Ph.D. student at MIT, advised by Martin Rinard.\nBefore coming here, I completed my M.S. in Computer Science at NYU, where I worked with Dennis Shasha on implementing AQuery, an optimizing compiler for order-related database queries. Before that, I worked for Morgan Stanley as part of the housing and mortgage research group. I graduated with a B.A. in Economics from University of Pennsylvania in 2011. I\u0026rsquo;m originally from San José, Costa Rica.\nI am currently working at the intersection of software engineering and machine learning, and am interested in exploring applied machine learning research. Recently, I have spent most of my time working on applications of machine learning to healthcare, in particular using Electronic Health Records for early prediction of pancreatic cancer diagnoses. This is joint work with researchers at Beth Israel Deaconess Medical Center.\nI have researched and published work on:\n optimizing database queries to perform dynamic imputation studying how developers use automatically generated bug patches using deep learning to improve code search using natural language applying active learning to infer and regenerate software using dynamic program analysis for automated machine learning  I\u0026rsquo;ve also worked on an assortment of other projects, such as using iOS data to customize image compression for users with color vision deficiencies, and performing large-scale color vision analysis across different countries.\nRecently, I interned at Facebook (Summer 2018) with the BigCode team, and spent Fall 2018 working part-time as a researcher (\u0026ldquo;Research Collaborator\u0026rdquo;) with the same team. I am actively looking for summer internship opportunities for Summer 2020.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://josecambronero.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m a fourth year Computer Science Ph.D. student at MIT, advised by Martin Rinard.\nBefore coming here, I completed my M.S. in Computer Science at NYU, where I worked with Dennis Shasha on implementing AQuery, an optimizing compiler for order-related database queries. Before that, I worked for Morgan Stanley as part of the housing and mortgage research group. I graduated with a B.A. in Economics from University of Pennsylvania in 2011.","tags":null,"title":"José Cambronero","type":"authors"},{"authors":["**José Cambronero**","Martin Rinard"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"abb035c6efab268406c739e94ae32f36","permalink":"https://josecambronero.com/publication/oopsla-2019/oopsla2019/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/oopsla-2019/oopsla2019/","section":"publication","summary":"We present AL, a novel automated machine learning system that learns to generate new supervised learning pipelines from an existing corpus of supervised learning programs. In contrast to existing automated machine learning tools, which typically implement a search over manually selected machine learning functions and classes, AL learns to identify the relevant classes in an API by analyzing dynamic program traces that use the target machine learning library. AL constructs a conditional probability model from these traces to estimate the likelihood of the generated supervised learning pipelines and uses this model to guide the search to generate pipelines for new datasets. Our evaluation shows that AL can produce successful pipelines for datasets that previous systems fail to process and produces pipelines with comparable predictive performance for datasets that previous systems process successfully.","tags":null,"title":"AL: Autogenerating Supervised Learning Programs","type":"publication"},{"authors":["**José Cambronero**","Thurston H.Y. Dang","Nikos Vasilakis","Jiasi Shen","Jerry Wu","Martin Rinard"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"296ed014146eed5c798bc7fbc8b91743","permalink":"https://josecambronero.com/publication/onward-2019/onward2019/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/onward-2019/onward2019/","section":"publication","summary":"Software applications have grown increasingly complex to deliver the features desired by users. Software modularity has been used as a way to mitigate the costs of developing such complex software. Active learning-based program inference provides an elegant framework that exploits this modularity to tackle development correctness, performance and cost in large applications. Inferred programs can be used for many purposes, including generation of secure code, code re-use through automatic encapsulation, adaptation to new platforms or languages, and optimization. We show through detailed examples how our approach can infer three modules in a representative application. Finally, we outline the broader paradigm and open research questions.","tags":null,"title":"Active Learning for Software Engineering","type":"publication"},{"authors":["**José Cambronero (1)**","Jiasi Shen (1)","Jürgen Cito (1)","Elena Glassman","Martin Rinard","(1: contributed equally)"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"c378787c9e819d1c183ac48aa4fc40d7","permalink":"https://josecambronero.com/publication/vlhcc-2019/vlhcc2019/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/vlhcc-2019/vlhcc2019/","section":"publication","summary":"We present a study that characterizes the way developers use automatically generated patches when fixing software defects. Our study tasked two groups of developers with repairing defects in C programs. Both groups were provided with the defective line of code. One was also provided with five automatically generated and validated patches, all of which modified the defective line of code, and one of which was correct. Contrary to our initial expectations, the group with access to the generated patches did not produce more correct patches and did not produce patches in less time. We characterize the main behaviors observed in experimental subjects: a focus on understanding the defect and the relationship of the patches to the original source code. Based on this characterization, we highlight various potentially productive directions for future developer-centric automatic patch generation systems.","tags":null,"title":"Characterizing Developer Use of Automatically Generated Patches","type":"publication"},{"authors":["**José Cambronero (1)**","Hongyu Li (1)","Seohyun Kim","Koushik Sen","Satish Chandra","(1: contributed equally)"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"d931cae3311b820a9650bcbf39713e04","permalink":"https://josecambronero.com/publication/fse-2019/fse2019/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/fse-2019/fse2019/","section":"publication","summary":"There have been multiple recent proposals on using deep neural networks for code search using natural language. Common across these proposals is the idea of embedding code and natural language queries, into real vectors and then using vector distance to approximate semantic correlation between code and the query. Multiple approaches exist for learning these embeddings, including unsupervised techniques, which rely only on a corpus of code examples, and supervised techniques, which use an aligned corpus of paired code and natural language descriptions. The goal of this supervision is to produce embeddings that are more similar for a query and the corresponding desired code snippet. Clearly, there are choices in whether to use supervised techniques at all, and if one does, what sort of network and training to use for supervision. This paper is the first to evaluate these choices systematically. To this end, we assembled implementations of state-of-the-art techniques to run on a common platform, training and evaluation corpora. To explore the design space in network complexity, we also introduced a new design point that is a minimal supervision extension to an existing unsupervised technique. Our evaluation shows that: 1. adding supervision to an existing unsupervised technique can improve performance, though not necessarily by much; 2. simple networks for supervision can be more effective that more sophisticated sequence-based networks for code search; 3. while it is common to use docstrings to carry out supervision, there is a sizeable gap between the effectiveness of docstrings and a more query-appropriate supervision corpus.","tags":null,"title":"When Deep Learning Met Code Search","type":"publication"},{"authors":null,"categories":null,"content":"","date":1504051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504051200,"objectID":"97261f34851a44239f7308282fec3822","permalink":"https://josecambronero.com/talk/vldb-2017/","publishdate":"2017-08-30T00:00:00Z","relpermalink":"/talk/vldb-2017/","section":"talk","summary":"Unfortunately I don't have a video of this talk, but the slides are available below. These were used for the talk about our work on query optimization for dynamic imputation.","tags":null,"title":"VLDB: Query Optimization for Dynamic Imputation","type":"talk"},{"authors":["**José Cambronero (1)**","John F. Feser (1)","Micah J. Smith (1)","Samuel Madden","(1: contributed equally)"],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"25aad7783e1b1f2db9b364147fab1344","permalink":"https://josecambronero.com/publication/vldb-2017/vldb2017/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/vldb-2017/vldb2017/","section":"publication","summary":"Missing values are common in data analysis and present a usability challenge. Users are forced to pick between removing tuples with missing values or creating a cleaned version of their data by applying a relatively expensive imputation strategy. Our system, ImputeDB, incorporates imputation into a cost- based query optimizer, performing necessary imputations on- the-fly for each query. This allows users to immediately explore their data, while the system picks the optimal placement of imputation operations. We evaluate this approach on three real-world survey-based datasets. Our experiments show that our query plans execute between 10 and 140 times faster than first imputing the base tables. Furthermore, we show that the query results from on-the-fly imputation differ from the traditional base-table imputation approach by 0–20%. Finally, we show that while dropping tuples with missing values that fail query constraints discards 6–78% of the data, on-the-fly imputation loses only 0–21%.","tags":null,"title":"Query Optimization for Dynamic Imputation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1474329600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1474329600,"objectID":"faf4d254646fe9acb9cded331bf09584","permalink":"https://josecambronero.com/talk/kx-meetup-2016/","publishdate":"2016-09-20T00:00:00Z","relpermalink":"/talk/kx-meetup-2016/","section":"talk","summary":"In this talk, Dennis Shasha and I present some of our work on AQuery, an optimizing compiler for order-related queries. I also provide a tutorial on implementing your own domain-specific language on top of kdb+/q","tags":null,"title":"Kdb+ User Meetup September 2016","type":"talk"}]
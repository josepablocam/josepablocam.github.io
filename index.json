[{"authors":["admin"],"categories":null,"content":"I recently defended my PhD at MIT, under the supervision of Martin Rinard. I\u0026rsquo;m starting a full-time position on Microsoft\u0026rsquo;s PROSE team this July 2021.\nYou can find a copy of my thesis here. The results of my thesis research also originally appeared in:\n using dynamic program analysis for automated machine learning (AutoML) generating AutoML search spaces using API docs and code corpora mining nearby transformations of machine learning pipelines to improve their performance  Closely relatedly, I have recently worked on:\n evaluating the empirical impact of downsampling as a way to scale genetic-programming-based AutoML to large datasets mining data wrangling functions from collections of Python programs written to work with the same dataset  I have also researched and published work on:\n optimizing database queries to perform dynamic imputation studying how developers use automatically generated bug patches using deep learning to improve code search using natural language applying active learning to infer and regenerate software developing a risk prediction model for pancreatic cancer using electronic health records  I spent the summer of 2020 as an intern with the SysML team at Facebook AI Research. Prior to that, I spent the summer of 2018 (as an intern) and the fall of 2018 (as a part-time research collaborator) with the Probability team at Facebook.\nBefore coming to MIT, I completed my M.S. in Computer Science at NYU, where I worked with Dennis Shasha on implementing AQuery, an optimizing compiler for order-related database queries. Before that, I worked for Morgan Stanley as part of the housing and mortgage research group. I graduated with a B.A. in Economics from University of Pennsylvania in 2011. I\u0026rsquo;m originally from San José, Costa Rica.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://josecambronero.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I recently defended my PhD at MIT, under the supervision of Martin Rinard. I\u0026rsquo;m starting a full-time position on Microsoft\u0026rsquo;s PROSE team this July 2021.\nYou can find a copy of my thesis here. The results of my thesis research also originally appeared in:\n using dynamic program analysis for automated machine learning (AutoML) generating AutoML search spaces using API docs and code corpora mining nearby transformations of machine learning pipelines to improve their performance  Closely relatedly, I have recently worked on:","tags":null,"title":"José Cambronero","type":"authors"},{"authors":["**José Cambronero**","Jürgen Cito","Micah J. Smith","Martin Rinard"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"a7685dc49be4130beef673dedf77c023","permalink":"https://josecambronero.com/publication/janus/janus/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/publication/janus/janus/","section":"publication","summary":"We frame the task of improving predictive performance of an existing machine learning pipeline by performing a small modification as an analogue to automated program repair. In this setting, the existence of a similar pipeline with better performance, the modification that delivers that improvement, and the task of automatically generating and applying that modification are the analogues of bug, patch, and automated program repair, respectively. We develop a system, Janus, that mines repair rules from a large corpus of pipelines, an approach conceptually similar to learning patches from code corpora. Our experiments show Janus can improve performance in 16%-42% of the test pipelines in our experiments, outperforming baseline approaches in 7 of the 9 datasets in our evaluation.","tags":null,"title":"Mining Nearby Repairs that Improve Machine Learning Pipeline Performance","type":"publication"},{"authors":["**José Cambronero**","Raul Casto Fernandez","Martin Rinard"],"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"4e5c89358ab03ac6c0fe7124df2bd3a5","permalink":"https://josecambronero.com/publication/wranglesearch/wranglesearch/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publication/wranglesearch/wranglesearch/","section":"publication","summary":"Analysts spend a substantial amount of time wrangling (i.e., preparing) data for their analyses. We present wranglesearch, a system that automatically extracts reusable data wrangling functions from a corpus of existing Python programs written to analyze a particular dataset. A new analyst can query wranglesearch’s function data- base to obtain wrangling functions that they can integrate into their own analyses, leveraging the wrangling efforts of prior analysts.","tags":null,"title":"wranglesearch: Mining Data Wrangling Functions from Python Programs","type":"publication"},{"authors":["Limor Appelbaum (equal contrib.)","**José Cambronero (equal contrib.)**","Jennifer P. Stevens","Steven Horng","Karla Pollick","George Silva","Sebastien Haneuse","Gail Piatkowski","Nordine Benhaga","Stacey Duey","Mary A. Stevenson","Harvey Mamon","Irving D. Kaplan","Martin Rinard"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"8d3b804f9f974dd5b39030a9ce627fa4","permalink":"https://josecambronero.com/publication/ejc-pdac/pdac/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/publication/ejc-pdac/pdac/","section":"publication","summary":"Aim: Pancreatic ductal adenocarcinoma (PDAC) is often diagnosed at a late, incurable stage. We sought to determine whether individuals at high risk of developing PDAC could be identified early using routinely collected data. Methods: Electronic health record (EHR) databases from two independent hospitals in Boston, Massachusetts, providing inpatient, outpatient, and emergency care, from 1979 through 2017, were used with case-control matching. PDAC cases were selected using International Classification of Diseases 9/10 codes and validated with tumour registries. A data-driven feature selection approach was used to develop neural networks and L2-regularised logistic regression (LR) models on training data (594 cases, 100,787 controls) and compared with a published model based on hand-selected diagnoses (‘baseline’). Model performance was validated on an external database (408 cases, 160,185 controls). Three prediction lead times (180, 270 and 365 days) were considered. Results: The LR model had the best performance, with an area under the curve (AUC) of 0.71 (confidence interval [CI]: 0.67-0.76) for the training set, and AUC 0.68 (CI: 0.65-0.71) for the validation set, 365 days before diagnosis. Data-driven feature selection improved results over 'baseline' (AUC 0.55; CI: 0.52-0.58). The LR model flags 2692 (CI 2592-2791) of 156,485 as high risk, 365 days in advance, identifying 25 (CI: 16-36) cancer patients. Risk stratification showed that the high-risk group presented a cancer rate 3 to 5 times the prevalence in our data set. Conclusion: A simple EHR model, based on diagnoses, can identify high-risk individuals for PDAC up to one year in advance. This inexpensive, systematic approach may serve as the first sieve for selection of individuals for PDAC screening programs.","tags":null,"title":"Development and validation of a pancreatic cancer risk model for the general population using electronic health records: An observational study","type":"publication"},{"authors":["Fatjon Zogaj (equal contrib.)","**José Cambronero (equal contrib)**","Martin Rinard","Jürgen Cito"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"6c369f4262f1c1d5b9d34278c2bffdc6","permalink":"https://josecambronero.com/publication/downsampling/downsampling/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/publication/downsampling/downsampling/","section":"publication","summary":"Automated machine learning (AutoML) promises to democratize machine learning by automatically generating machine learning pipelines with little-to-no user intervention. Typically, a search procedure is used to repeatedly generate and validate candidate pipelines, maximizing a predictive performance metric, subject to a limited execution time budget. While this approach to generating candidates works well for small datasets, the same procedure does not directly scale to larger datasets with 100,000s of observations, often producing fewer candidate pipelines and yielding lower performance. We empirically investigate downsampling as a way to mitigate this challenge. Our evaluation on 16 datasets (4 smaller datasets with less than 10,000 observations and 12 large datasets with 50,000 to over 1,000,000 observations) shows that for a widely-used AutoML search procedure downsampling increases the number of pipelines evaluated and improves the predictive performance of the final pipeline. More specifically, we find that for most of the larger datasets (11 out of 12), the sampling ratio yielding the best predictive performance is between 0.05 and 0.2. We also see that aggressive downsampling ratios can lead to up to 20x more pipelines being explored by the search procedure as compared to performing search with the full dataset. Interestingly, in a control experiment where we performed search for 60 minutes (instead of 5 minutes) on the full dataset, we find that resulting predictive performance still underperforms the pipeline resulting from a 5 minute search on the downsampled dataset. The release of an extensive reproducibility package, along with our empirical insights, open up the possibility to generate and investigate additional theoretical hypotheses in future analyses.","tags":null,"title":"Doing More with Less: Characterizing Dataset Downsampling for AutoML","type":"publication"},{"authors":["**José Cambronero**","Jürgen Cito","Martin Rinard"],"categories":null,"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"0f8ad9619a5c08d2566f3cae63b5ec7c","permalink":"https://josecambronero.com/publication/fse-2020/fse2020/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/publication/fse-2020/fse2020/","section":"publication","summary":"We consider a usage model for automated machine learning (AutoML) in which users can influence the generated pipeline by providing a *weak pipeline specification*: an unordered set of API components from which the AutoML system draws the components it places into the generated pipeline. Such specifications allow users to express preferences over the components that appear in the pipeline, for example a desire for interpretable components to appear in the pipeline.  We present AMS, an approach to automatically strengthen weak specifications to include unspecified complementary and functionally related API components, populate the space of hyperparameters and their values, and pair this configuration with a search procedure to produce a *strong pipeline specification*: a full description of the search space for candidate pipelines. AMS uses normalized pointwise mutual information on a code corpus to identify complementary components, BM25 as a lexical similarity score over the target API's documentation to identify functionally related components, and frequency distributions in the code corpus to extract key hyperparameters and values. We show that strengthened specifications can produce pipelines that outperform the pipelines generated from the initial weak specification and an expert annotated variant, while producing pipelines that still reflect the user preferences captured in the original weak specification.","tags":null,"title":"AMS: Generating AutoML search spaces from weak specifications","type":"publication"},{"authors":["**José Cambronero**","Martin Rinard"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"abb035c6efab268406c739e94ae32f36","permalink":"https://josecambronero.com/publication/oopsla-2019/oopsla2019/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/oopsla-2019/oopsla2019/","section":"publication","summary":"We present AL, a novel automated machine learning system that learns to generate new supervised learning pipelines from an existing corpus of supervised learning programs. In contrast to existing automated machine learning tools, which typically implement a search over manually selected machine learning functions and classes, AL learns to identify the relevant classes in an API by analyzing dynamic program traces that use the target machine learning library. AL constructs a conditional probability model from these traces to estimate the likelihood of the generated supervised learning pipelines and uses this model to guide the search to generate pipelines for new datasets. Our evaluation shows that AL can produce successful pipelines for datasets that previous systems fail to process and produces pipelines with comparable predictive performance for datasets that previous systems process successfully.","tags":null,"title":"AL: Autogenerating Supervised Learning Programs","type":"publication"},{"authors":["**José Cambronero**","Thurston H.Y. Dang","Nikos Vasilakis","Jiasi Shen","Jerry Wu","Martin Rinard"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"296ed014146eed5c798bc7fbc8b91743","permalink":"https://josecambronero.com/publication/onward-2019/onward2019/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/onward-2019/onward2019/","section":"publication","summary":"Software applications have grown increasingly complex to deliver the features desired by users. Software modularity has been used as a way to mitigate the costs of developing such complex software. Active learning-based program inference provides an elegant framework that exploits this modularity to tackle development correctness, performance and cost in large applications. Inferred programs can be used for many purposes, including generation of secure code, code re-use through automatic encapsulation, adaptation to new platforms or languages, and optimization. We show through detailed examples how our approach can infer three modules in a representative application. Finally, we outline the broader paradigm and open research questions.","tags":null,"title":"Active Learning for Software Engineering","type":"publication"},{"authors":["**José Cambronero (1)**","Jiasi Shen (1)","Jürgen Cito (1)","Elena Glassman","Martin Rinard","(1: contributed equally)"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"c378787c9e819d1c183ac48aa4fc40d7","permalink":"https://josecambronero.com/publication/vlhcc-2019/vlhcc2019/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/vlhcc-2019/vlhcc2019/","section":"publication","summary":"We present a study that characterizes the way developers use automatically generated patches when fixing software defects. Our study tasked two groups of developers with repairing defects in C programs. Both groups were provided with the defective line of code. One was also provided with five automatically generated and validated patches, all of which modified the defective line of code, and one of which was correct. Contrary to our initial expectations, the group with access to the generated patches did not produce more correct patches and did not produce patches in less time. We characterize the main behaviors observed in experimental subjects: a focus on understanding the defect and the relationship of the patches to the original source code. Based on this characterization, we highlight various potentially productive directions for future developer-centric automatic patch generation systems.","tags":null,"title":"Characterizing Developer Use of Automatically Generated Patches","type":"publication"},{"authors":["**José Cambronero (1)**","Hongyu Li (1)","Seohyun Kim","Koushik Sen","Satish Chandra","(1: contributed equally)"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"d931cae3311b820a9650bcbf39713e04","permalink":"https://josecambronero.com/publication/fse-2019/fse2019/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/fse-2019/fse2019/","section":"publication","summary":"There have been multiple recent proposals on using deep neural networks for code search using natural language. Common across these proposals is the idea of embedding code and natural language queries, into real vectors and then using vector distance to approximate semantic correlation between code and the query. Multiple approaches exist for learning these embeddings, including unsupervised techniques, which rely only on a corpus of code examples, and supervised techniques, which use an aligned corpus of paired code and natural language descriptions. The goal of this supervision is to produce embeddings that are more similar for a query and the corresponding desired code snippet. Clearly, there are choices in whether to use supervised techniques at all, and if one does, what sort of network and training to use for supervision. This paper is the first to evaluate these choices systematically. To this end, we assembled implementations of state-of-the-art techniques to run on a common platform, training and evaluation corpora. To explore the design space in network complexity, we also introduced a new design point that is a minimal supervision extension to an existing unsupervised technique. Our evaluation shows that: 1. adding supervision to an existing unsupervised technique can improve performance, though not necessarily by much; 2. simple networks for supervision can be more effective that more sophisticated sequence-based networks for code search; 3. while it is common to use docstrings to carry out supervision, there is a sizeable gap between the effectiveness of docstrings and a more query-appropriate supervision corpus.","tags":null,"title":"When Deep Learning Met Code Search","type":"publication"},{"authors":null,"categories":null,"content":"","date":1504051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504051200,"objectID":"97261f34851a44239f7308282fec3822","permalink":"https://josecambronero.com/talk/vldb-2017/","publishdate":"2017-08-30T00:00:00Z","relpermalink":"/talk/vldb-2017/","section":"talk","summary":"Unfortunately I don't have a video of this talk, but the slides are available below. These were used for the talk about our work on query optimization for dynamic imputation.","tags":null,"title":"VLDB: Query Optimization for Dynamic Imputation","type":"talk"},{"authors":["**José Cambronero (1)**","John F. Feser (1)","Micah J. Smith (1)","Samuel Madden","(1: contributed equally)"],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"25aad7783e1b1f2db9b364147fab1344","permalink":"https://josecambronero.com/publication/vldb-2017/vldb2017/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/vldb-2017/vldb2017/","section":"publication","summary":"Missing values are common in data analysis and present a usability challenge. Users are forced to pick between removing tuples with missing values or creating a cleaned version of their data by applying a relatively expensive imputation strategy. Our system, ImputeDB, incorporates imputation into a cost- based query optimizer, performing necessary imputations on- the-fly for each query. This allows users to immediately explore their data, while the system picks the optimal placement of imputation operations. We evaluate this approach on three real-world survey-based datasets. Our experiments show that our query plans execute between 10 and 140 times faster than first imputing the base tables. Furthermore, we show that the query results from on-the-fly imputation differ from the traditional base-table imputation approach by 0–20%. Finally, we show that while dropping tuples with missing values that fail query constraints discards 6–78% of the data, on-the-fly imputation loses only 0–21%.","tags":null,"title":"Query Optimization for Dynamic Imputation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1474329600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1474329600,"objectID":"faf4d254646fe9acb9cded331bf09584","permalink":"https://josecambronero.com/talk/kx-meetup-2016/","publishdate":"2016-09-20T00:00:00Z","relpermalink":"/talk/kx-meetup-2016/","section":"talk","summary":"In this talk, Dennis Shasha and I present some of our work on AQuery, an optimizing compiler for order-related queries. I also provide a tutorial on implementing your own domain-specific language on top of kdb+/q","tags":null,"title":"Kdb+ User Meetup September 2016","type":"talk"}]